---
title: "RF_Prep"
author: "Daniel Dominguez"
date: '2023-05-25'
output: html_document
editor_options: 
  chunk_output_type: console
---
### The best way to describe how the training framework works/ was designed is by thikning about car engine tuning for an automatic transmission. As the DOC (or water quality parameter) increases the AI model switches similar to what occurs when you step on the gas and the car switches gears. In this case each of the AI models can be thought about as a gear in the transmission. The statistics of another AI predicting a measurement in a different quanitle also back up how this works but will be explained below. 

```{r}
local_Path <- "/Users/danieldominguez/Documents/Code/DOC_WSC/Data/"

```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(feather)
library(viridis)
library(sf)
library(mlbench)
library(caret)
library(xgboost)
library(Metrics)
library(purrr)
library(data.table)
library(mltools)
library(ggthemes)
library(dplyr)
library(ggplot2)
library(scales)
library(dplyr)
library(kableExtra)

```


```{r prep}
# filter data
data <- read.csv(paste0(local_Path, "aquasat_processed.csv")) %>%
  #filter(!is.na(doc)) %>% # remove rows without DOC data
  filter(!is.na(doc) & !is.na(secchi)) %>% # (option) filtering out rows without DOC and Secchi
  filter(pwater >= 80) %>% #filter for mostly water pixels
  filter(!type == "Facility") %>% #not enough data to be representative when splitting betwen quanitles
  #filter(n>=10) %>% # (option) filter if there is not at least x readings for a site for better training
  filter(pixelCount > 0) %>% #filter erroneous pixel counts
  mutate(value = doc) %>%  #mutate doc to target value
  filter_all(all_vars(!is.infinite(.))) %>% # remove rows with infinites that might have resulted from band calculations
  mutate(
    WC = case_when(
      red < green & red > blue ~ "Green",
      red > green & nir > 0.01 ~ "Brown",
      green < blue ~ "BG",
      TRUE ~ "Green"
    )
  ) # Create water color classification based on literature
  
```

```{r}
bands <- c("red", "green","blue", "swir1", "swir2","nir",
  "NR", "BR", "GR", "SR", "BG", "RG", "NG", "SG", "BN", "GN",
  "RN", "SN", "BS", "GS", "RS", "NS", "RGN", "RGB", "RGS", "RBN",
  "RBS", "RNS", "GBR", "GBN", "GBS", "GRN", "GRB", "GNS",
  "BRG", "BRS", "BGN", "BGS", "BNS", "NRG", "NRB", "NRS",
  "NGB", "NGS", "NBS", "GR2", "GN2", "B_RG", "NS_NR", "fai",
  "N_S", "N_R", "NDVI", "NDWI", "NDSSI", "GNGN"
)# (option)All available bands
```


```{r}

# select featuers
features <- c("red", "blue","GS","green",
              "swir1","swir2","SG","RBS","NGS","GBS","GR2","GN2", "GRB","N_R",
              "NR","N_S", "RGB","ecoregion", "type","season","WC")  #Narrower features

filtered_data <- data %>%
  dplyr::select(features, value, uniqueID,ecoregion, type,season,WC,secchi) %>% 
  mutate_if(is.character,as.factor) 

#This will create a "magnitude label if below a threshold low if above high for better train test split 
filtered_data$mag <- ifelse(filtered_data$value <= 40, "low", "high")

# This will write the full filtered dataset which can then be split in the python files
write.csv(filtered_data,paste0(local_Path,"aquasat_full.csv"),row.names=FALSE)

```

```{r}
random_filter_data <- function(df, column_name, condition, filter_percentage, seed ) {
  # Set a random seed for reproducibility
  if (!is.null(seed)) {
    set.seed(seed)
  }
  
  # Create a logical vector indicating whether rows satisfy the condition
  mask <- sapply(df[[column_name]], condition)
  
  # Randomly select the indices to keep based on the filter_percentage
  num_to_keep <- round(sum(mask) * (1 - filter_percentage))
  indices_to_keep <- sample(which(mask), num_to_keep)
  
  # Filter the DataFrame based on the selected indices
  filtered_df <- df[indices_to_keep, ]
  
  return(filtered_df)
}
```


```{r}

# this is an experimental split I was using to artificially reduce the amount of low observations similar to Gardner et al., 2023
rf_data_low<-random_filter_data(filtered_data, 'value', function(x) x > 0 & x < 10, filter_percentage = 0.95, seed = 01) %>% 
  dplyr::select(features, value, uniqueID,ecoregion, type,season,WC,secchi) %>% 
  mutate(mag="low")

rf_data_med<-random_filter_data(filtered_data, 'value', function(x) x > 10 & x < 40, filter_percentage = 0.9, seed = 01) %>% 
  dplyr::select(features, value, uniqueID,ecoregion, type,season,WC,secchi)%>% 
  mutate(mag="low")

#We keep all the data that is a high outlier
rf_data_high<- data %>% 
  filter(value>=40) %>% 
  dplyr::select(features, value, uniqueID,ecoregion, type,season,WC,secchi)%>% 
  mutate(mag="high")

rf_data<-rbind(rf_data_low,rf_data_med,rf_data_high)

#write.csv(rf_data,paste0(local_Path,"rf_aquasat_full.csv"),row.names=FALSE)  

```


```{r}
# Pre split the data into train and test for better stratification sampling

set.seed(15) # set seed for reproducibility

train_v1 <- filtered_data %>%
  group_by( mag) %>%
  sample_frac(.8) %>%
  ungroup() %>%
  arrange(value)
  
# Select all uniqueID's not selected in the training set
test_v1 <- filtered_data %>%
  filter(!(uniqueID %in% train_v1$uniqueID)) %>%
  arrange(value)
  
write.csv(train_v1,paste0(local_Path,"DOC_train_v1.csv"),row.names=FALSE)

write.csv(test_v1,paste0(local_Path,"DOC_test_v1.csv"),row.names=FALSE)
    
    
```

