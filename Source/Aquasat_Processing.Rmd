---
title: "Aquasat_Processing"
author: "Daniel Dominguez"
date: '2023-06-07'
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r}
local_Path <- "Data/"

```


```{r setup, include=FALSE}
library(tidyverse)
library(sf)
library(dplyr)
library(mapview)
```


# Download Aquasat File

Check for presence of Aquasat matchup file - if it doesn't exist, download it.

```{r}

url <- "https://figshare.com/ndownloader/files/18733733"
name <- "sr_wq_rs_join.csv"
if (file.exists(file.path(local_Path, name))) {
  "The Aquasat file has already been downloaded."
} else {
  # the download will take some time.
  options(timeout=10000)
  download.file(url = url, 
                destfile = file.path(local_Path, name))
  "The Aquasat file has been downloaded"
}
```

# High-level QAQC

```{r}
# Filter RS data to reasonable range (0-2000), images with at least 8 pixels
RS <- read_csv(file.path(local_Path,"sr_wq_rs_join.csv")) %>% #tidy, number of pixels contributing as a cutoff
  filter(red<2000 & red>0) %>% 
  filter(green<2000 &green>0) %>% 
  filter(blue<2000 &blue>0) %>% 
  filter(swir1<2000 &swir1>0) %>% 
  filter(swir2<2000 &swir2>0) %>% 
  filter(nir<2000 & nir>0) %>% 
  mutate(NR=nir/red, #calculate the bands in JG new study
         BR=blue/red,
         GR=green/red,
         SR=swir1/red,
         BG=blue/green,
         RG=red/green,
         NG=nir/green,
         SG=swir1/green,
         BN=blue/nir,
         GN=green/nir,
         RN=red/nir,
         SN=swir1/nir,
         BS=blue/swir1,
         GS=green/swir1,
         RS=red/swir1,
         NS=nir/swir1,
         RGN=red/(green+nir),
         RGB=red/(green+blue),
         RGS=red/(green+swir1),
         RBN=red/(blue+nir),
         RBS=red/(blue+swir1),
         RNS=red/(nir+swir1),
         GBR=green/(blue+swir1),
         GBN=green/(blue+nir),
         GBS=green/(blue+swir1),
         GRN=green/(red+nir),
         GRB=green/(red+blue),
         GNS=green/(nir+swir1),
         BRG=blue/(red+green),
         BRS=blue/(red+swir1),
         BGN=blue/(green+nir),
         BGS=blue/(green+swir1),
         BNS=blue/(nir+swir1),
         NRG=nir/(red+green),
         NRB=nir/(red+blue),
         NRS=nir/(red+swir1),
         NGB=nir/(green+blue),
         NGS=nir/(green+nir),
         NBS=nir/(blue+swir1),
         GR2=(red+green)/2,
         GN2=(nir+green)/2,
         B_RG=(blue-red)/green,
         NS_NR=(nir-swir1)/(red-swir1),
         fai=nir - (red + (swir1-red)*((830-660)/(1650-660))),
         N_S=nir-swir1,
         N_R=nir-red,
         NDVI=((nir - red)/(nir + red)),
         NDWI=((green - swir1)/(green + swir1)),
         NDSSI=((blue - nir)/ (blue + nir)),
         GNGN=((green- nir)/ (green + nir))) %>% 
    mutate(uniqueID = row_number())
```

```{r}

  dplyr::mutate(uniqueID = row_number())%>% # remove rows with infinites that might have resulted from band calculations
  mutate(
    WC = case_when(
      red < green & red > blue ~ "Green",
      red > green & nir > 0.01 ~ "Brown",
      green < blue ~ "BG",
      TRUE ~ "Green"
    )
  )


## Read in and convert the sites to extract the ecoregion they are located in
sites <- RS %>% 
  select(SiteID,lat, long, type) %>%  
  unique() %>% 
  st_as_sf(coords=c("long","lat"), crs=4269) 


url <- "https://gaftp.epa.gov/EPADataCommons/ORD/Ecoregions/cec_na/na_cec_eco_l1.zip"
name <- "na_cec_eco_l1.zip"
if (file.exists(file.path(local_Path, "ecoregions/NA_CEC_Eco_Level1.shp"))) {
  "The ecoregion file has already been downloaded."
} else {
  dir.create(file.path(local_Path, "ecoregions"))
  download.file(url = url, 
                destfile = file.path(local_Path, "ecoregions", name))
  unzip(file.path(local_Path, "ecoregions", name), 
        exdir = file.path(local_Path, "ecoregions"))
  unlink(file.path(local_Path, "ecoregions", name))
}


EcoRegions<-st_read(dsn=paste0(local_Path,"ecoregions/NA_CEC_Eco_Level1.shp")) 


EcoRegions <- st_read(dsn=paste0(local_Path,"ecoregions/NA_CEC_Eco_Level1.shp")) #Load ecoregions

EcoRegions_sf <- EcoRegions %>% 
  st_transform(crs = 4269) %>% 
  st_make_valid() #Extract the ecoregion for each site
  
Ecoregions_buffer<-EcoRegions_sf %>% 
  st_buffer( dist = 1)


```

```{r}
#Extract the ecoregion for each site
site_ecoregions<-st_join(sites,EcoRegions_sf) # merge the ecoregion to dataset

ggplot(site_ecoregions, aes(color = NA_L1NAME, shape = type)) + 
  geom_sf()

Sites_remaining<-site_ecoregions %>% 
  filter(is.na(NA_L1NAME)) %>% 
  select(-NA_L1NAME,-NA_L1CODE,-NA_L1KEY,-Shape_Leng,-Shape_Area)

sites_ecoregion_buffered<-st_join(Sites_remaining,Ecoregions_buffer)

sites_ecoregion_buffered[is.na(sites_ecoregion_buffered)] <- "COASTAL"# mutate the NA category that is sites along the coastline to Coastal for ecoregion grouping

# Deduplicate based on SiteID
deduplicated_site_ecoregions <- sites_ecoregion_buffered %>%
  as.data.frame() %>% 
  group_by(SiteID) %>%
  mutate(n_ecoregions = n_distinct(NA_L1NAME)) %>%
  distinct(SiteID, .keep_all = TRUE) %>%
  select(SiteID,NA_L1NAME)


site_ecoregions <- site_ecoregions %>% 
  mutate(NA_L1NAME = if_else(is.na(NA_L1NAME),
                             "COASTAL",
                             NA_L1NAME))
# site_ecoregions[is.na(site_ecoregions)] <- "COASTAL"# mutate the NA category that is sites along the coastline to Coastal for ecoregion grouping

site_ecoregions <- site_ecoregions %>% 
  as.data.frame() %>% 
  select(SiteID,
         ecoregion=NA_L1NAME)

site_ecoregions<-rbind(site_ecoregions,deduplicated_site_ecoregions) %>%  
  dplyr::select(SiteID,ecoregion=NA_L1NAME) %>% 
  filter(!is.na(ecoregion)) 


RS <- left_join(RS,site_ecoregions,by="SiteID")# Join ecoregions to dataset
```

<<<<<<< HEAD
Apply season string to date 
=======
>>>>>>> d23f4a7 (fixed coastal sites)

```{r}
get_season <- function(date_str) {
  month <- month(date_str)
  
  # Determine the season based on the month following water year; Fall October-December and so on
  if (month %in% c(1, 2, 3)) {
    return("Winter")
  } else if (month %in% c(4, 5, 6)) {
    return("Spring")
  } else if (month %in% c(7, 8, 9)) {
    return("Summer")
  } else {
    return("Fall")
  }
}

RS <- RS %>%
  mutate(season = map(date, get_season))
```


```{r}
site_count<-RS %>% 
  group_by(SiteID) %>% 
  summarise(n=n())# count how many observations per site there is for filtering later

RS<-left_join(RS,site_count,by="SiteID") # join to dataset

write_csv(RS, file.path(local_Path,"aquasat_processed.csv"))

```

